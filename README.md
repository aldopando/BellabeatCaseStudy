# BellabeatCaseStudy

## Phases of data analysis process about Bellabeat Ivy 


## Ask 


**What is the problem you are trying to solve?**  

Identify trends and patterns from overall smart devices usage data in order to draw insights and how they may apply in a Bellabeat product**  	
 
**How can your insights drive business decisions?**

My insights can influence in how to address the new Bellabeat marketing strategy.

  

**Business Task**

*Draw meaningful insights from smart device usage trends and how they can impact on Bellabeat marketing strategy*


## Prepare

**About the data**
These datasets were generated by respondents to a distributed survey via Amazon Mechanical Turk between 03.12.2016-05.12.2016. Thirty eligible Fitbit users consented to the submission of personal tracker data, including minute-level output for physical activity, heart rate, and sleep monitoring.
Prepare Guiding questions
 
 - Where is your data stored?   
 **Data is stored in a collection of datasets on Kaggle**
 **This collection contains several tables across different metrics of personal tracker data**
 **This collection is broken down into two folders,  both with same metrics but each folder contains data in different periods of time**

 - How is the data organized? Is it in long
   or wide format?  
   **The data is organized in two folders, each folder representing a different period of time:**
   
	 - First Folder (11 tables) **2016/03/11 - 2016/04/11** 
		 - `dailyActivity_merged.csv` 
			 - The dataset is in **wide format**.

				-   Each data subject `id` has a row of a combination of multiple attributes such as `TotalSteps, TotalDistance, TrackerDistance, etc`.
				    
				-   Variables are spread across the columns. Columns represent different metrics like steps, distance, active minutes, etc.
				- Each variable has its own column.

		 - `heartrate_seconds_merged.csv`  
			 - The dataset is in **long format**.

				-   Each row is a single observation of the variable `heart rate value`   by a specific user `id` at a specific time `Time`.
				    
				-  The subject user `id` is repeated across multiple rows to represent the value `heart rate`  at different points of time `Time`
				
		- `hourlyCalories_merged.csv`
			- The dataset is in **long format**.
				-  Each row is a single observation of the variable `number of calories burnt`   by a specific user `id` at a specific time `ActivityHour`.
				    
				-  The subject user `id` is repeated across multiple rows to represent a value of `Calories`  at different hours `ActivityHour`.
		
		- `hourlyIntensities_merged.csv`
			- The dataset is in **long format**. It has more than column apparently representing more than one variable. In reality, the second column represents an aggregate function to calculate the **average** of intensity state exhibited during a specific hour by the user. In other words, the column `AverageIntensity` is the statistical summary of the variable `TotalIntensity`.  Therefore, this dataset only contains one variable where each row represents one observation of this variable at a specific time.

		- `hourlySteps_merged.csv` - The dataset is in **long format**.
  
		- `minuteCaloriesNarrow_merged.csv` - The dataset is in **long format**.
     
		- `minuteIntensitiesNarrow_merged.csv` - The dataset is in **long format**.
     			
		- `minuteMETsNarrow_merged.csv` - The dataset is in **long format**.
			
		- `minuteSleep_merged.csv`
			- The dataset is in **wide format**.  Each row represents a unique combination of identifiers (user **id**, **date** and **logId**).
			
		- `minuteStepsNarrow_merged.csv` - The dataset is in **long format**
		
		- `weightLogInfo_merged.csv`
			- The dataset is in **wide format**. Each data subject `id` has a row of a combination of multiple attributes such as `WeightKg, WeightPounds, Fat, BMI, IsManualReport, LogId`

	- Second Folder  (18 tables) **2016/04/11 - 2016/05/11** 
		 - `dailyActivity_merged.csv*` - The dataset is in **wide format**.
			
		 - `dailyCalories_merged.csv` - The dataset is in **long format**.
		
		- `dailyIntensities_merged.csv`
			- The dataset is in **wide format**. In this dataset there is a combination of multiple columns representing attributes for each row. Each column has its own variable.  A single row has atributes such as `SedentaryMinutes, LightlyActiveMinutes, VeryActiveMinutes, ModeratelyActiveDistance, etc.`
		
		- `dailySteps_merged.csv` - The dataset is in **long format**.
			
		- `heartrate_seconds_merged.csv` - The dataset is in **long format**.
			
		- `hourlyCalories_merged.csv` - The dataset is in **long format**.
			
		- `hourlyIntensities_merged.csv` - The dataset is in **long format**.
			
		- `hourlySteps_merged.csv` - The dataset is in **long format**.
			
		- `minuteCaloriesNarrow_merged.csv` - The dataset is in **long format**.
			
		- `minuteCaloriesWide_merged.csv`
			- The dataset is in **wide format**.  *It has multiple columns that contain the same type of data for different time points.*  For example, columns for `"Calories00", "Calories01", "Calories02"... "Calories59"`  
			E.g.
			***Calories05 = calories burned in fifth minute of the hour.***
			
		- `minuteIntensitiesNarrow_merged.csv`
			- The dataset is in **long format**. The same data as "minuteCaloriesWide_merged.csv" but in long format. **The time points (minutes) are spread out through the rows.**
			
		- `minuteIntensitiesWide_merged.csv` - The dataset is in **wide format**.
			
		- `minuteMETsNarrow_merged.csv` - The dataset is in **long format**.
			
		- `minuteSleep_merged.csv` - The dataset is in **wide format**.
			
		- `minuteStepsNarrow_merged.csv` - The dataset is in **long format**.
			
		- `minuteStepsWide_merged.csv` - The dataset is in **wide format**.
			
		- `sleepDay_merged.csv`
			- The dataset is in **wide format**. The number of rows in this dataset can initially suggest a "long" format, especially when it can be observed many repeated IDs or timestamps. But **the format (wide vs. long) is not defined by the number of rows**. it’s defined by **how the variables are organized**
Each row of this dataset is a summary of many variables (`TotalSleepRecords, TotalMinutesAsleep, TotalTimeInBed `) for a specific time `SleepDay`

			
		- `weightLogInfo_merged.csv` - The dataset is in **wide format**.

****
 - Are there issues with bias or credibility in this data? Does your
   data ROCCC?
   
    **Reliability**
	   
	 - ***Uncertainty about bias in the data***: The authors of this dataset doesn't share any information about how participants were chosen for the sample. Therefore, we cannot make sure if the data was collected using random sampling to fairly have a good representation of the population. 
	 - **Small sample**:  This dataset has a sample size of 30 users. Even though it has been statistically proven that 30 is the smallest sample size where an average result of a sample starts to represent the average result of a population, this dataset is at borderline of this minimum number. A larger sample size would have been better to get more accurate and reliable results from analysis,specially in very large market. According to [statista](https://www.statista.com/forecasts/1425172/fitness-tracker-users-by-segment-us), In 2024, there were around 62 million fitness tracker users in the United States (35% women). In the near future, the number of fitness tracker users is forecast to steadily increase, jumping to over 92 million by 2029. 



    **Original**
   
    The dataset is ***third-party data*** , shared by the user *Möbius* on Kaggle. 
    Möbius has attached the link of the original source which it comes from an **open data source**, under a **Creative Commons Attribution 4.0 International license**. meaning anyone can copy, distribute, remix, and build upon the material for any purpose, even commercially, as long as you give credit for the original creators. 
     In other words, you can have accessibility to the **original data source** under a permissive license to give credit to the **original authors** who collect and generate this dataset.
  
    **Comprehensive**
  
    ***Critical Information needed to solve the business task***
    The Bellabeat app provides users with health data related to their activity, sleep, stress, menstrual cycle, and mindfulness habits. This data can help users better understand their current habits and make healthy decisions. The Bellabeat app connects to their line of smart wellness products
    
    ***Data contained in FitBit Fitness Tracker  datasets***
    FitBit Fitness Tracker Data contains user's information about their heart rate, sleep monitoring, daily activity by tracking totals for steps, intensity, distance, calories, and logged activities.
    We can make sure that the datasets utilized for this analysis cover most of the important metrics that Bellabeat uses to provide insights about its user's health and wellness.
    We are lacking of specific information about reproductive health data for women, but this is an exclusive feature that Bellabeat offers compared to other brands. 
  
    ***Completeness***
    
     - **Small sample size**: The sample size fall short, using only *thirty people* as sample size of a huge population that every year is growing more and more. 
     - **Short period of time**: The data collection was released during two months 2016/03/12 - 2016/05/12. This period of time might be a limitation to track noticeable changes in user's routine. According to [James Clear](https://jamesclear.com/new-habit#:~:text=On%20average%2C%20it%20takes%20more,to%20form%20a%20new%20habit.), "***On average, it takes more than 2 months before a new behavior becomes automatic — 66 days to be exact.** And how long it takes a new habit to form can vary widely depending on the behavior, the person, and the circumstances. In Lally’s study, it took anywhere from 18 days to 254 days for people to form a new habit.*"
  
  
  
    **Current**
   
    Checking the dataset *FitBit Fitness Tracker Data* in its original source, we notice that the last time updated was May 31, 2016. This data is out of date, which it means that the data is less relevant to the current time this analysis is being performed.
    
    **Cited**
  
    These datasets were created by *Robert, Brinton Furberg, Julia Brinton, Michael Keating and Alexa Ortiz*, published and hosted via Zenodo website, a reliable open repository. 
    The data was collected by a distributed survey via Amazon Mechanical Turk between 03/12/2016-05/12/2016. 
  
     *Citation*
    Furberg, R., Brinton, J., Keating, M., & Ortiz, A. (2016). Crowd-sourced Fitbit datasets 03.12.2016-05.12.2016 [Data set]. Zenodo.
    [https://doi.org/10.5281/zenodo.53894](https://doi.org/10.5281/zenodo.53894)
****
 - How are you addressing licensing, privacy, security, and
   accessibility?
  
 ### Authors
 Furberg, Robert.
 Brinton, Julia.
 Keating, Michael.
 Ortiz, Alexa.
 
 ### Citation
   
   Furberg, R., Brinton, J., Keating, M., & Ortiz, A. (2016). Crowd-sourced Fitbit datasets 03.12.2016-05.12.2016 [Data set]. Zenodo.
  
  ### Rights

**License**

 ![cc-by-4.0 icon](https://zenodo.org/static/icons/licenses/cc-by-icon.svg)  
[Creative Commons Attribution 4.0 International](https://creativecommons.org/licenses/by/4.0/legalcode)
   
   ****
  
 - How does it help you answer your question?     
 
*FitBit Fitness Tracker Data* contain all critical information (such as heart rate, sleep monitoring, and daily activity) to draw insights, identify patterns and trends into how people how people are using wearable devices. It is cited as well and comes from an original and reliable source. The dataset is structured and organized to start cleaning the data and performing analysis.


****
 -  Are there any problems with the data?
 
**Problems and limitations with the data**:

-   **Small sample size:**  This dataset has a sample size of 30 users. The market of people using wearable devices is huge (80 million just in USA) and growing each year. This can be a limitation to get an accurate result of the sample that fairly represents the entire population.  
-   **Out of date**: The data was generated since 2016, making it more irrelevant due to  the analysis is being conducted in 2025.
-   **Limited period of time:** This period of time might be a limitation to track any change in user's routine, which is essential to identify outliers and have a more complete representation of patterns and tends people have in their wellness and daily activity.
-   **Possible biased sample:** The sample may not be a fair representation of the population. We don't have accessibility to details about how participants were eligible to the survey. 
-   **Lack of demographic data**: Age and gender are not specified, this is essential information because Bellabeat products are targeted to women. 
- **Lack of reproductive health data**: Bellabeat tracks reproductive data such as menstrual cycle, pregnancy and fertility. Nevertheless, this dataset doesn't contain any information about these type of metrics.


 **Possible missing data or inconsistencies: Must be checked during processing.**

Key tasks 
1. Download data and store it appropriately. 
2. Identify how it’s organized. 
3. Sort and filter the data. 
4. Determine the credibility of the data. 

**Deliverable.**
 A description of all data sources used


## Process 

Process Guiding questions 
- What tools are you choosing and why? 
**Cleaning data**.
I decided to process and clean the data using SQL because SQL 
- Have you ensured your data’s integrity? 

**Changelog**
Author: Aldair Pichon Aguila.
 
1. I downloaded the datasets from Kaggle in my local machine. 05/20/2025
2. I renamed the two main folders that contain the datasets to ensure better clarity, consistency and organization of the data following guidelines of naming conventions:
	Fitabase Data 3.12.16-4.11.16  ->   FitabaseData_20160312-20160411
	Fitabase Data 4.12.16-5.12.16  ->  FitabaseData_20160412-20160512
  05/20/2025
  
3. I created a new project in BigQuery named `analysisbellabeat246` and two datasets for each of the two folders. 05/20/2025
4. When uploading the table `heartrate_seconds_merged.csv` and checking the auto-detect box to automatically set the schema for this table in BigQuery, then it tries to parse the column `"Time"` as TIMESTAMP data type. Due to the original format of `"Time"`  is one that BigQuery cannot recognized as TIMESTAMP, it returns an error.  To fix this problem, rather than BigQuery auto detecting the schema of the table, I manually specified the schema in JSON format and defining the column `"Time"` as STRING instead of TIMESTAMP.
In order to figure out the name, data type and description of each column I referred to the document [Fitbit Data Dictionary](https://www.fitabase.com/media/2088/fitabase-fitbit-data-dictionary-as-of-4524.pdf). 05/20/2025
 
 
	    [  
			{  
				"description": "Id",  
				"mode": "NULLABLE",  
				"name": "Id",  
				"type": "INTEGER"  
			},  
			{  
				"description": "Time",  
				"mode": "NULLABLE",  
				"name": "Time",  
				"type": "STRING"  
			},  
			{  
				"description": "Value",  
				"mode": "NULLABLE",  
				"name": "Value",  
				"type": "INTEGER"  
			}  
		]

5. I uploaded the rest of tables through manually writing the schema in JSON format for the datasets `FitabaseData_20160312-20160411` and `FitabaseData_20160412-20160512`.
    [Here](SchemaTables.md) you can find the code in JSON format to define the schemma of tables uploaded in BigQuery. Except for the tables `dailyCalories`,  `dailyIntensities`, and `dailySteps`. Their schema created automatically by BigQuery due to it didn't have problems to parse them.
    05/21/2025
 
6. When uploading the tables into the dataset `FitabaseData_20160412-20160512`, I decided to add `_secondPeriod` at the end of each table's name to distinguish these tables from the tables of the `FitabaseData_20160312-20160411` dataset . It will avoid any confusion in the future when merging the tables. This is important because after downloading the datasets from Kaggle I noticed that some table's name repeat across the two folders representing the same information but in different periods of time. 05/21/2025
   
    E.g.
    
    	 `FitabaseData_20160312-20160411 -> heartrate_seconds_merged.csv`
    	 `FitabaseData_20160412-20160512 -> heartrate_seconds_merged.csv`
    	 
    Renamed tables after uploading in BigQuery 
    
    	 `FitabaseData_20160312-20160411 -> heartrate_seconds.csv`
    	 `FitabaseData_20160412-20160512 -> heartrate_seconds_secondPeriod.csv`


7.  Checking for NULL values in each table. In order to figure out how to address possible NULL values in the data, first I need to know if they exist at all and in what columns. I counted the null values for each column in each table of the project. [Here](checkingNulls.md) you can see the queries used and the results in each table. We discovered that only the table "weightLogInfo" in both datasets contain NULL values in the "Fat" column, which is the field for recording the body fat percentage. In the first dataset, 31 out of 33 rows contain NULL values and in the second one, 65 out of 67 rows. Even though some participants data was measured and synched automatically using a scale connected to the Fitbit account, it seems that the version of scale that they used wasn't able to measure and display any information about body fat percentage. The two participants whose body fat percentage was inputted, it was recorded manually. Unfortunely, almost all records in this column contain NULL values, so I decided to remove this column for analysis. Body fat percentage could have been very useful to provide valuable insights about overall health and help make informed decisions about fitness and nutrition goals. Nevertheless, we still have information about BMI metrics and weight for analysis.
   05/26/2025

8. Before deciding which tables to use for the analysis, I went over several of them to determine whether they provide accurate and complete information and are consistent with other tables. 

9. Checking for consistency between minute tables in each dataset.  Allegedlly, each minute table contains a specific metric (calories, steps, METs, intensities, and sleep) that was tracked simultaniously at the same time and for the same users (Id) along with the other metrics. Therefore, I decided to compare and see if the tables contain the same users Id and during the same periods of time. For this task, I used SQL along with pivot tables in Google sheets. [Here](https://github.com/aldopando/BellabeatCaseStudy/blob/main/consistency.md#checking-for-consistency-between-calories-intensity-mets-steps-and-sleep-in-minute-tables) you will see the steps and results about the consistency between minute tables. The results shown that `minuteCalories`,`minuteIntensities`, `minuteMETs`, and `minuteSteps` are consistent between them in both datasets. The information of these tables was recorded simultaneously during the same period of time and with the same users. The `minuteSleep` table is not consistent with the rest of the minute tables, because the data of this table was logged only for some users out of the 33 participants. Hence, `minuteSleep` table is going to be analyze individually.
  05/27/2025    

10. After ensuring the consistency within the minute tables, we proceeded to check the consistency within the hourly tables. By doing this, we can streamline the process by selecting just one minute table and one hourly table for the comparison. **I want to figure out if hourly tables were generated by agreggating the data from minutes to hours**. [Here](https://github.com/aldopando/BellabeatCaseStudy/blob/main/consistency.md#checking-for-consistency-in-hour-tables-calories-intensity-and-steps) you can find the process and results done for checking consistency within hourly tables. We discovered that all hourly tables are consistent each other in both datasets.
    05/27/2025

11. Afterward, I compared the minute and hourly tables to verify whether they represent the same data, aggregated using different time measures. You can find the method and results for this comparison [here](https://github.com/aldopando/BellabeatCaseStudy/blob/main/consistency.md#checking-for-consistency-minutes-vs-hourly-tables).We found that the minute and hourly tables within the `FitabaseData_20160312_20160411` dataset are consistent, meaning they represent the same data. Although we observed differences in the total values between the `minuteCalories` and `hourlyCalories` tables for each user, this inconsistency is due to the data types: `minuteCalories` contains float values (with decimals), while `hourlyCalories` contains integer values. This is because the `minuteCalories` table was created by dividing the calories per hour values by 60, to represent the number of calories burned per minute, which results in decimal values. **Now that we know that minute and hourly tables tables are consistent, I decided to only use the hourly tables for analysis**
In the `FitabaseData_20160412_20160512` dataset, we found inconsistencies between the hourly and minute tables because some users stopped tracking their data at different times in each table. This led to inconsistent total values between the minute and hourly tables.This is unusual, as the hourlyCalories table is supposedly built based on the minuteCalories data. **To address this inconsistency, we decided to not use the hourly tables from the second dataset, instead we will stick with the minute tables and based on them building the hourly tables by ourselves**.
    05/28/2025

12. The `dailyActivity` table in each dataset contains daily totals for steps, intensity, distance, and calories. I assume that the minute and hourly tables are subsets of the `dailyActivity table`. If this table represents the same data as the minute and hourly tables, I might use it for analysis to draw insights about users’ daily activity and health, instead of grouping the data into days manually using the minute and hourly tables. After checkig wheter the `dailyActivity` table is consistent with minute and hour tables, we discovered it is not. Although the `dailyActivity` table covers a time period very similar to the minute and hourly tables, the differences are significant enough to confirm that they are not fully consistent. You can check the process and results [here](https://github.com/aldopando/BellabeatCaseStudy/blob/main/consistency.md#checking-consistency-in-dailyactivity-tables).
**The `dailyActivity` table is not consistent with the rest of minute and hour tables. Therefore, I decided not to use it for our analysis, instead I will build a daily table using the minutes and hourly data**
  05/29/2025

13. However, `hourlyintensities` tables don't contain the `SedentaryMinutes`, `LightlyActiveMinutes`, `FairlyActiveMinutes`, and `VeryActiveMinutes ` columns  to represent the time spent in one of four intensity categories:

Intensity value for the given minute.

0 = Sedentary

1 = Light

2 = Moderate

3 = Very Active


These colunmns are important for our analysis, therefore, we are gonna use the "minuteIntensities" tables from both datasets to calculate the values of these columns and add them in new "hourlyIntensities" tables. In other words, we a won't use the "hourlyIntensities" tables already present in the datasets. We will use the "minuteIntensities" tables four our analysis  to create the hourly and daily tables by ourselves. 05/29/2025

14. After ensuring the data is consistent across the tables in each dataset and contains no NULL values, the following tables have been selected for analysis:


 ### FitabaseData_20160312_20160411 dataset 

| Table  |
| --- |
| hearrate_seconds |
| hourlyCalories |
| minuteIntensitiesNarrow |
| hourlySteps |
| minuteMETsNarrow |
| minuteSleep |
| weightLogInfo |



### FitabaseData_20160412_20160512 dataset

| Table |
| --- |
| heartrate_seconds_secondPeriod |
| minuteCaloriesNarrow_secondPeriod
| minuteIntensitiesNarrow_secondPeriod |
| minuteMETsNarrow_secondPeriod |
| minuteStepsNarrow_secondPeriod |
| minuteSleep_secondPeriod |
| weightLogInfo_secondPeriod |


15. For this analysis, it is important to draw insights and identify patterns that emerged throughout the entire survey period. Therefore, having a complete view of the data is essential. This means I need to merge the tables from the first dataset with those from the second. To do this, I will use the foreign key (user_id) contained in the tables. However, before merging, I need to verify whether the tables contain the same users across both datasets. [Here](https://github.com/aldopando/BellabeatCaseStudy/blob/main/Merging.md#checking-user-consistency-across-datasets-before-merging-tables) you will find the queries and results used for this cleaning process. 05/30/2025
    
    - weightLogInfo: more than half of the participants are missing weight data in one of the datasets, resulting in incomplete information. Additionally, I didn't observe any significant changes in users' weight during the two-month period. For the users who tracked their weight data, the data was recorded sporadically. Therefore, we decided to include all available weight data from both datasets, regardless of whether some users are missing weight information in one of them. Our goal is to use the weight data as an overall indicator of the participants' health status during the survey.  
    - minuteSleep: there are 3 out of 25 participants that are missing sleep data in one of the two datasets. However, this represents a small portion of the overall available sample (although the sample size itself is smaller than what is statistically recommended to fairly represent a population), we will merge the datasets to include only the users who are present in both datasets, resulting in a final sample of 22 participants.
    - calories, intensities, METs and Steps: there are 3 out of 25 participants who are missing data across these tables in one of the two datasets. Nevertheless, this does not represent a major issue in terms of completeness within the available sample. Therefore, we will merge the datasets to include only the users who are present in both datasets, resulting in a final sample of 32 participants.


16. Before merging the tables from both datasets, I will create the new "hourlyIntensities" tables based on the "minuteIntensitiesNarrow" tables.

**FitabaseData_20160312_20160411 dataset**

Query.

	SELECT
	  Id,
	  TIMESTAMP_TRUNC(activityMinute, HOUR) AS activityHour,
	  SUM(Intensity) AS TotalIntensity,
	  ROUND(AVG(Intensity), 1) AS AverageIntensity,
	  COUNTIF(Intensity = 0) AS SedentaryMinutes,
	  COUNTIF(Intensity = 1) AS LightlyActiveMinutes,
	  COUNTIF(Intensity = 2) AS FairlyActiveMinutes,
	  COUNTIF(Intensity = 3) AS VeryActiveMinutes 
	
	FROM ( 
	  SELECT 
	    Id,
	    PARSE_TIMESTAMP('%m/%d/%Y%I:%M:%S %p', ActivityMinute) AS activityMinute,
	    Intensity
	
	  FROM `analysisbellabeat246.FitabaseData_20160312_20160411.minuteIntensitiesNarrow`
	)
	
	GROUP BY Id, activityHour


I saved the results as a new table called `hourlyIntensities_complete` in this dataset.


**FitabaseData_20160412_20160512 dataset**

Query.

	SELECT
	  Id,
	  TIMESTAMP_TRUNC(activityMinute, HOUR) AS activityHour,
	  SUM(Intensity) AS TotalIntensity,
	  ROUND(AVG(Intensity), 1) AS AverageIntensity,
	  COUNTIF(Intensity = 0) AS SedentaryMinutes,
	  COUNTIF(Intensity = 1) AS LightlyActiveMinutes,
	  COUNTIF(Intensity = 2) AS FairlyActiveMinutes,
	  COUNTIF(Intensity = 3) AS VeryActiveMinutes 
	
	FROM ( 
	  SELECT 
	    Id,
	    PARSE_TIMESTAMP('%m/%d/%Y%I:%M:%S %p', ActivityMinute) AS activityMinute,
	    Intensity
	
	  FROM `analysisbellabeat246.FitabaseData_20160412_20160512.minuteIntensitiesNarrow_secondPeriod` 
	)
	
	GROUP BY Id, activityHour


I saved the results as a new table called `hourlyIntensities_secondPeriod_complete` in this dataset.


15. I merged the next tables from the two datasets to get the new merged tables. [Here](https://github.com/aldopando/BellabeatCaseStudy/blob/main/Merging.md#merging-tables) you will find the file with the queries performed to merge the tables. 05/31/2025
    
    | Table || Result |
    | --- | --- | --- |
    | weightLogInfo | weightLogInfo_secondPeriod | weight_data |
    | minuteSleep | minuteSleep_secondPeriod | minuteSleep_merged |
    | hourlyCalories | minuteCaloriesNarrow_secondPeriod | hourlyCalories_merged |
    | hourlyIntensities_complete | hourlyIntensities_secondPeriod_complete | hourlyIntensities_merged |
    | hourlySteps | minuteStepsNarrow_secondPeriod | hourlySteps_merged |
    | minuteMETsNarrow | minuteMETsNarrow_secondPeriod | minuteMETs_merged |

16. After merging the tables from the two datasets, I checked for extra spaces or characters across the records of each merged table. [Here](https://github.com/aldopando/BellabeatCaseStudy/blob/main/cleaning.md#extra-spaces-in-data) you can find all the queries and steps performed to check for extra spaces in the merged tables. **We didn't find any extra spaces or characters in the analyzed columns**. 06/01/2025

17. Finally, I checked for duplicates in the merged tables to finish the cleaning process of this data. [Here](https://github.com/aldopando/BellabeatCaseStudy/blob/main/cleaning.md#duplicates-in-data) you will find the process and results for cleaning duplicates in the data. Since BigQuery doesn't allow updates or deletions of individual rows in standard tables, we will create a dataset that will storage the cleaned version of the tables that contain only distinct rows. This dataset is named `clean_data`. 06/02/2025
    
	- hourlyCalories_merged: 175 duplicate rows were removed.
  	- hourlyIntensities_merged: 175 duplicate rows were removed.
	- hourlySteps_merged:  175 duplicate rows were removed.
	- minuteMETs_merged: 10,500 duplicate rows were removed.
	- weight_data: 2 duplicate rows were removed.
  	- minuteSleep_merged: 4,300 duplicate rows were removed.


### Clean_data dataset

| Table |
| --- | 
| hourlyCalories_cleaned |
| hourlyIntensities_cleaned |
| hourlySteps_cleaned |
| minuteMETs_cleaned |
| weight_data_cleaned |
| minuteSleep_cleaned |


## Analysis

### Aggregating METs from minutes to hours

For this analysis, we will aggregate the data in the `minuteMETs_cleaned` table from minutes to hours in order to merge it along with the other variables (calories, intensities and steps). We will save the results as a new table called `hourlyMETs_cleaned` in our `clean_data` dataset.

To aggregate the variable METs, we will have to sum all MET minutes a person expends during an hour. 

Important: All MET values exported from Fitabase are multiplied by 10. We will divide by 10 to get accurate MET values.

Example: 10 = 1.0 METs; 38 = 3.8 METs


**What is a MET?**

MET stands for Metabolic Equivalent of Task. It is a unit that measures how much energy an activity consumes compared to being at rest. Low-intensity exercises have a lower MET value while high-intensity physical activities have a high MET score.

**Levels of MET**

We can differentiate 3 categories of physical activity:

Light-intensity activities – under 3 MET;
Moderate–intensity activities – from 3 to 6 MET;
Vigorous–intensity activities – over 6 MET.

**What is a MET minute?**

Met-Minutes are used to determine the amount of energy expended during a workout or activity. A MET minute is the amount of energy expended during a minute while at rest.  You can, however, burn more than one MET minute in a minute depending on the intensity of the activity.

**MET minutes per week**

The amount of MET minutes per week tells you how much energy you have expended while performing various activities throughout the whole week.


**World Health Organization guidelines on physical activity and sedentary behaviour**

Currently, the [World Health Organization](https://www.who.int/publications/i/item/9789240015128) recommends adults to meet a minimum physical activity: 

- Adults should aim for at least 150 minutes of moderate-intensity activity or 75 minutes of vigorous-intensity activity per week for minimal health benefits. 
- For additional health benefits, adults should increase their moderate-intensity physical activity to 300 minutes per week or an equivalent

According to [the Skeptical Cardiologist](https://theskepticalcardiologist.com/2021/01/17/the-compendium-of-physical-activities-mets-for-all/) article:
Moderate-intensive activities are ones that cause you to consume at least three times but no more than six times as much energy per minute as you do at rest. Thus moderate intensity exercises or activities are those which require 3-6 METS like walking at 3-4 MPH.

Vigorous activities such as running at >6 MPH burn > 6 METS.

**how many MET minutes is enough?**

Accordig to [omni calculator](https://www.omnicalculator.com/sports/met-minutes-per-week?utm_source=chatgpt.com) website:

MET-minutes/week is a measure used to quantify intentional physical activity, not basic physiological processes like sleeping or resting. Only activities over 3 MET can be considered when counting active minutes per week.

This means that you need at least 450 MET minutes per week to meet these recommendations. Moreover, if we take into account the second recommendation to achieve extra health benefits, you should achieve at least 900 MET minutes per week.

***Therefore, to calculate the MET-minutes for each user in this case study, we will only count the values equal or greater than 3 METs for a more accurate approach to physical activity.*** 


Query.


	CREATE TABLE clean_data.hourlyMETs_cleaned AS
	
	SELECT 
	
	  Id,
	  TIMESTAMP_TRUNC(activityMinute, HOUR) AS activityHour,
	  SUM(CASE WHEN METs/10 > 3 THEN METs ELSE 0 END)/10 AS MET_minutes
	
	FROM `analysisbellabeat246.clean_data.minuteMETs_cleaned` 
	
	GROUP BY Id, TIMESTAMP_TRUNC(activityMinute, HOUR)

---


### We created a new dataset called `analysis` to save all the results after performing calculations and aggregating the data.


### Merging hourly tables (calories, intensities, steps, and METs) + Sorting the data.
 

Query. 

	SELECT  
	  calories.Id,
	  calories.activityHour,
	  calories.Calories,
	  intensities.TotalIntensity,
	  intensities.SedentaryMinutes,
	  intensities.LightlyActiveMinutes,
	  intensities.FairlyActiveMinutes,
	  intensities.VeryActiveMinutes,
	  METs.MET_minutes,
	  steps.StepTotal
	
	FROM `analysisbellabeat246.clean_data.hourlyCalories_cleaned` AS calories
	
	LEFT JOIN `analysisbellabeat246.clean_data.hourlyIntensities_cleaned` AS intensities 
	  ON calories.Id = intensities.Id 
	  AND calories.activityHour = intensities.activityHour
	
	LEFT JOIN `analysisbellabeat246.clean_data.hourlyMETminutes_cleaned` AS METs 
	  ON calories.Id = METs.Id 
	  AND calories.activityHour = METs.activityHour
	
	LEFT JOIN `analysisbellabeat246.clean_data.hourlySteps_cleaned` AS steps
	  ON calories.Id = steps.Id 
	  AND calories.activityHour = steps.activityHour
	
	ORDER BY Id, activityHour



***We saved the results as a new table called `hourlyActivity` in our `analysis` dataset***


**Verifying number of rows**

| hourlyCalories_cleaned | hourlyIntensities_cleaned | hourlyMETs_cleaned | hourlySteps_cleaned | hourlyActivity  |
| --- | --- | --- | --- | --- |
| 44,580 | 44,580 | 44,580 | 44,580 | 44,580 |




### Aggregating the data in the `hourlyActivity` table from hours to days + Sorting the data.


	SELECT  
		Id,
		DATE(TIMESTAMP_TRUNC(activityHour, DAY)) AS activityDate,
		SUM(Calories) AS calories,
		SUM(TotalIntensity) AS totalIntensity,
		SUM(SedentaryMinutes) AS sedentaryMinutes,
		SUM(LightlyActiveMinutes) AS lightlyActiveMinutes,
		SUM(FairlyActiveMinutes) AS fairlyActiveMinutes,
		SUM(VeryActiveMinutes)AS veryActiveMinutes,
		CAST(SUM(MET_minutes) AS INT64) AS MET_minutes,
		SUM(StepTotal) AS totalSteps
		
		
	FROM `analysisbellabeat246.analysis.hourlyActivity` 
		
	GROUP BY Id, activityDate
	ORDER BY Id, activityDate


***We saved the results as a new table called `dailyActivity` in our `analysis` dataset***


### Oldest and latest date

**Oldest date**


Query.

	SELECT  
	  Id,
	  MIN(activityHour) AS oldest_date
	
	FROM `analysisbellabeat246.analysis.hourlyActivity` 
	
	GROUP BY Id


Results.

| Id | oldest_date | 
| --- | --- |
| 1503960366 |	2016-03-12 00:00:00.000000 UTC |
| 1624580081 |	2016-03-12 00:00:00.000000 UTC |
| 1644430081 |	2016-03-12 00:00:00.000000 UTC |
| 1844505072 |	2016-03-12 00:00:00.000000 UTC |
| 1927972279 |	2016-03-12 00:00:00.000000 UTC |
| 2022484408 |	2016-03-12 00:00:00.000000 UTC |
| 2026352035 |	2016-03-12 00:00:00.000000 UTC |
| 2320127002 |	2016-03-12 00:00:00.000000 UTC |
| 2347167796 |	2016-03-12 00:00:00.000000 UTC |
| 2873212765 |	2016-03-12 00:00:00.000000 UTC |
| 3372868164 |	2016-03-12 00:00:00.000000 UTC |
| 3977333714 |	2016-03-12 00:00:00.000000 UTC |
| 4020332650 |	2016-03-12 00:00:00.000000 UTC |
| 4057192912 |	2016-03-12 00:00:00.000000 UTC |
| 4319703577 |	2016-03-12 00:00:00.000000 UTC |
| 4445114986 |	2016-03-12 00:00:00.000000 UTC |
| 4558609924 |	2016-03-12 00:00:00.000000 UTC |
| 4702921684 |	2016-03-12 00:00:00.000000 UTC | 
| 5553957443 |	2016-03-12 00:00:00.000000 UTC |
| 5577150313 |	2016-03-12 00:00:00.000000 UTC |
| 6117666160 |	2016-03-12 00:00:00.000000 UTC |
| 6290855005 |	2016-03-12 00:00:00.000000 UTC |
| 6775888955 |	2016-03-12 00:00:00.000000 UTC |
| 6962181067 |	2016-03-12 00:00:00.000000 UTC |
| 7007744171 |	2016-03-12 00:00:00.000000 UTC |
| 7086361926 |	2016-03-12 00:00:00.000000 UTC |
| 8053475328 |	2016-03-12 00:00:00.000000 UTC |
| 8253242879 |	2016-03-12 00:00:00.000000 UTC |
| 8378563200 |	2016-03-12 00:00:00.000000 UTC |
| 8583815059 |	2016-03-12 00:00:00.000000 UTC |
| 8792009665 |	2016-03-12 00:00:00.000000 UTC |
| 8877689391 |	2016-03-12 00:00:00.000000 UTC |

---

**Latest date**

First, we found the latest date when the data was tracked across all users.

Query.

	SELECT  
	  MAX(activityDate) AS latest_date
	
	FROM `analysisbellabeat246.analysis.dailyActivity` 
 

 Results.

| latest_date |
| --- |
| 2016-05-12 |


We counted how many users finished to track their data in the date 2016-05-12.


Query. 

	SELECT 
	  COUNTIF(latest_date = '2016-05-12') AS latest_date_2016_05_12
	
	FROM (
	  SELECT  
	    Id,
	    MAX(activityDate) AS latest_date
	
	  FROM `analysisbellabeat246.analysis.dailyActivity` 
	
	  GROUP BY Id
	)


Results.

| latest_date_2016_05_12 |
| --- |
| 18 |


Observations.

***Only 18 participants finished to track their data in 2016-05-12***


### Number of users that weekly tracked their data throughout the period time (March 12 to May 12).


We grouped the days and assinged them into a corresponding week. The first week started since 2016-03-12. Every week contains 7 days, except the week 9 which contains only 6 days.

Query.

	SELECT 
	  CASE 
	  WHEN activityDate BETWEEN '2016-03-12' AND '2016-03-18' THEN 'Week 1'
	  WHEN activityDate BETWEEN '2016-03-19' AND '2016-03-25' THEN 'Week 2'
	  WHEN activityDate BETWEEN '2016-03-26' AND '2016-04-01' THEN 'Week 3'
	  WHEN activityDate BETWEEN '2016-04-02' AND '2016-04-08' THEN 'Week 4'
	  WHEN activityDate BETWEEN '2016-04-09' AND '2016-04-15' THEN 'Week 5'
	  WHEN activityDate BETWEEN '2016-04-16' AND '2016-04-22' THEN 'Week 6'
	  WHEN activityDate BETWEEN '2016-04-23' AND '2016-04-29' THEN 'Week 7'
	  WHEN activityDate BETWEEN '2016-04-30' AND '2016-05-06' THEN 'Week 8'
	  ELSE 'Week 9'   
	  END AS week,
	  COUNT(DISTINCT(Id)) AS active_users
		
	FROM `analysisbellabeat246.analysis.dailyActivity` 
		
	GROUP BY week
	ORDER BY week

---

![image](https://github.com/user-attachments/assets/472a1897-b50e-4115-9d8c-69163e2759e3)


Observations.

- ***We can observe a considerable decline of users that were consistently tracking their data in the end of the period (week 7 to week 9)***.


---

## Identifying inactivity patterns.

**First approach**.

We know that all Fitbit devices track **steps** taken. When a person is using their wearable, it automatically starts to tracked their steps. We can assumme that a person can accomplish a minimum amount of steps during a day that is different from zero, even for a sedentary person. If the value of steps taken is zero, it means the user is not using their wearable. Therefore, we can pinpoint the users who didn't wear their devices in specifc days by identifying if they got zero steps taken.

Therefore, we will filter out all the rows where total steps are zero in our `dailyActivity` table and observe what values were tracked in the other variables when this happened. 

Query. 

	SELECT *

	FROM `analysisbellabeat246.analysis.dailyActivity`
	
	WHERE totalSteps = 0
	
	ORDER BY MET_minutes DESC



We sorted the data by MET-minutes to identify any outlier because our hypothesis is that if a user got zero steps during a day, it means they wasn't using their wearable, Therefore, their devices couldn't have tracked any intensity (physical activity) either.


<img width="1740" height="644" alt="image" src="https://github.com/user-attachments/assets/369b3947-d8b9-44b7-8bc9-7488a2818e36" />

---

- ***We found two users whose devices tracked high intensity levels and MET-minutes even though they got zero steps in that day. We can infer that they only used their wearables to tracked a non-step activity such as weight lifting. We know that the devices that can tracked heart rate data are particularly useful for activities that are not easily tracked by steps alone, such as weightlifting, yoga, swimming, or rowing.***

  
**Second approach**

We cannot only base on steps taken variable to identify users who weren't using their wearables, because there were users who were involved in non-step activities. Therefore, to fairly identify users totally inactive (they weren't using their wearables in certain days at all) we need to filter out:

The users who got 0 steps taken AND 0 total intensity AND 0 MET-minutes in a day.

Query.

	SELECT *
	
	FROM `analysisbellabeat246.analysis.dailyActivity`
	
	WHERE totalSteps = 0 AND totalIntensity = 0 AND MET_minutes = 0
	
	ORDER BY MET_minutes DESC



<img width="1808" height="328" alt="image" src="https://github.com/user-attachments/assets/a5a66c25-9f1f-4a0b-92dd-ee3e6431e613" />


- ***We found 220 rows of non-activity (days when users weren't using their wearables)***.
- ***We can still see values in the `calories` column because this variable represents the BMR which stands for basal metabolic rate. It is the number of calories a person needs to stay alive. This value is calculated automatically by the system (even though the user isn't using the wearable) based on information logged about users' physical characteristics such as age, sex, height, and weight***.
- ***We can still see values in the `sedentaryMinutes` column because sedentary minutes are added up when the intensity is equal to zero. And it makes sense, because 1440 minutes represents 24 hours, meaning 24 hours of 0 intensity.***.
  

---

**To fairly draw insights from the data, we need to only take into account the days when the participants were using their devices**.

---

## Inactivity by day of the week.

We are going to figure out what days there were more inactivity levels (when participants didn't use their wearables). 

Query.

	WITH inactivity_days AS (
	
	  SELECT 
	    Id,
	    activityDate,
	    FORMAT_DATE('%A', activityDate) AS day_of_the_week
	
	  FROM `analysisbellabeat246.analysis.dailyActivity`
	
	  WHERE totalSteps = 0 AND totalIntensity = 0 AND MET_minutes = 0
	
	  ORDER BY Id, activityDate
	)
	
	SELECT 
	  day_of_the_week,
	  COUNT(Id) AS inactive_users
	
	FROM inactivity_days
	
	GROUP BY day_of_the_week
	ORDER BY inactive_users

 ![image](https://github.com/user-attachments/assets/a4a9a00f-9191-40f4-9ea7-a93d7dd73b8d)


 **Observations**.

 - ***The days with more inactivity (when users didn't use their device at all) were Saturday and Sunday***.
 - ***Monday and Tuesday are days with high levels of inactivity as well***.
 - ***Friday is the day when users were using their devices more consistenly*** .




### Steps

**Weekly inactivity patterns: days with 0 steps**

We know that all Fitbit devices track **steps** taken. When a person is using their wearable, it automatically starts to tracked their steps. We can assumme that a person can accomplish a minimum amount of steps during a day that is different from zero, even for a sedentary person. If the value of steps taken is zero, it means the user is not using their wearable. Therefore, we can pinpoint the users who didn't wear their devices in specifc days by identifying if they got zero steps taken.


First off, we will create a table that contains the users who tracked 0 steps in any day throughout the two months period. Moreover, we will count how many days each user happen to have 0 steps during each week.

Query.

	SELECT 
	  Id,
	  CASE
	  WHEN activityDate BETWEEN '2016-03-12' AND '2016-03-18' THEN 'Week 1'
	  WHEN activityDate BETWEEN '2016-03-19' AND '2016-03-25' THEN 'Week 2'
	  WHEN activityDate BETWEEN '2016-03-26' AND '2016-04-01' THEN 'Week 3'
	  WHEN activityDate BETWEEN '2016-04-02' AND '2016-04-08' THEN 'Week 4'
	  WHEN activityDate BETWEEN '2016-04-09' AND '2016-04-15' THEN 'Week 5'
	  WHEN activityDate BETWEEN '2016-04-16' AND '2016-04-22' THEN 'Week 6'
	  WHEN activityDate BETWEEN '2016-04-23' AND '2016-04-29' THEN 'Week 7'
	  WHEN activityDate BETWEEN '2016-04-30' AND '2016-05-06' THEN 'Week 8'
	  ELSE 'Week 9'
	  END AS week,
	  COUNTIF(TotalSteps = 0) AS totalDays_notStepsTracked
	
	
	FROM `analysisbellabeat246.analysis.dailyActivity` 
	
	GROUP BY Id, week
	HAVING COUNTIF(TotalSteps = 0) > 0
	ORDER BY Id, week



![image](https://github.com/user-attachments/assets/5d2d36ec-7a34-4904-86b0-6931a7cbd7de)


---

Observations
- ***We can observe that 6 users got zero steps taken for a whole week, this means that 6 users didn't use their wearables during taht week***.
- ***We can also see that 20 participants stopped using their devices at some point of the period time***.
- ***4 users tracked zero steps for two whole weeks. In other words, four participants didn't use their wearable at all for two weeks***.

---

Now we will group our users who didn't give any step based on how many days they were inactive, and we will count the total users in each group by week.

Query.

	SELECT 
	  week,
	  COUNTIF(totalDays_notStepsTracked = 7) AS seven_days,
	  COUNTIF(totalDays_notStepsTracked = 6) AS six_days,
	  COUNTIF(totalDays_notStepsTracked = 5) AS five_days,
	  COUNTIF(totalDays_notStepsTracked = 4) AS four_days,
	  COUNTIF(totalDays_notStepsTracked = 3) AS three_days,
	  COUNTIF(totalDays_notStepsTracked = 2) AS two_days,
	  COUNTIF(totalDays_notStepsTracked = 1) AS one_day,
	
	FROM (
	  SELECT 
	    Id,
	    CASE
	    WHEN activityDate BETWEEN '2016-03-12' AND '2016-03-18' THEN 'Week 1'
	    WHEN activityDate BETWEEN '2016-03-19' AND '2016-03-25' THEN 'Week 2'
	    WHEN activityDate BETWEEN '2016-03-26' AND '2016-04-01' THEN 'Week 3'
	    WHEN activityDate BETWEEN '2016-04-02' AND '2016-04-08' THEN 'Week 4'
	    WHEN activityDate BETWEEN '2016-04-09' AND '2016-04-15' THEN 'Week 5'
	    WHEN activityDate BETWEEN '2016-04-16' AND '2016-04-22' THEN 'Week 6'
	    WHEN activityDate BETWEEN '2016-04-23' AND '2016-04-29' THEN 'Week 7'
	    WHEN activityDate BETWEEN '2016-04-30' AND '2016-05-06' THEN 'Week 8'
	    ELSE 'Week 9'
	    END AS week,
	    COUNTIF(TotalSteps = 0) AS totalDays_notStepsTracked
	
	  FROM `analysisbellabeat246.analysis.dailyActivity` 
	
	  GROUP BY Id, week
	  HAVING COUNTIF(TotalSteps = 0) > 0
	  ORDER BY Id, week
	)
	
	GROUP BY week
	ORDER BY week


![image](https://github.com/user-attachments/assets/821f8760-ffe1-4ffa-b208-f26bbf6807f2)


Observations.

- ***We can observe a peak of 5 users who didn't give any steps during 7 days (an entire week) in the week 2***.
- ***The week with most inactive users was the second***.
- ***During the week 5, there were less inactive users, meaning the users were using their wearable more frequently compared to other weeks***.


**Average daily steps by user**

According to [10000 Steps](https://www.10000steps.org.au/learn-and-discover/counting-steps/#:~:text=Sedentary%20is%20less%20than%205%2C000,is%20approximately%203%2C000%20%2D%204%2C000%20steps.), studies using the 10,000 steps per day goal have shown weight loss, improved glucose tolerance, and reduced blood pressure from increased physical activity toward achieving this goal. 

However, a general guideline for daily physical activity based on step count is:

- Sedentary is less than 5,000 steps per day. 
- Low active is 5,000 to 7,499 steps per day.
- Somewhat active is 7,500 to 9,999 steps per day.
- Active is more than 10,000 steps per day.
- Highly active is more than 12,500  steps per day.


To fairly draw insights from the analysis we will filter out only the values tracked when the participants were using their wearables, meaning when they didn't get 0 steps, 0 MET-minutes and 0 total intensity.


Query.

	SELECT  
	  Id,
	  ROUND(AVG(TotalSteps), 0) AS average_TotalSteps
	
	FROM `analysisbellabeat246.analysis.dailyActivity` 
	
	WHERE totalSteps != 0 AND totalIntensity != 0 AND MET_minutes != 0
	
	GROUP BY Id
	ORDER BY Id


![image](https://github.com/user-attachments/assets/314cb4bc-af77-46fb-8ef0-b34ccaa0b143)

 
Observations.

- ***We can observe that on average 8 participants reached the daily goal of 10,000 steps for a good overall health, representing the 25% of the total sample.***.
- ***It means that 75% are under the daily goal of 10,000 steps. However, this goal is not universally appropriate across all ages and physical function. Besides that, we are not taking into account non-step activities***

---

Query.

	SELECT 
	  CASE
	  WHEN average_TotalSteps < 5000 THEN 'Sedentary'
	  WHEN average_TotalSteps BETWEEN 5000 AND 7499 THEN 'Low active'
	  WHEN average_TotalSteps BETWEEN 7500 AND 9999 THEN 'Somewhat active'
	  WHEN average_TotalSteps BETWEEN 10000 AND 12499 THEN 'Active'
	  ELSE 'Highly active'
	  END AS physical_activity,
	  COUNT(Id) AS number_of_users
	
	FROM(
	  SELECT  
	    Id,
	    ROUND(AVG(TotalSteps), 0) AS average_TotalSteps
	
	  FROM `analysisbellabeat246.analysis.dailyActivity` 
	
	  WHERE totalSteps != 0 AND totalIntensity != 0 AND MET_minutes != 0
	
	  GROUP BY Id
	  ORDER BY Id
	)
	GROUP BY physical_activity
	ORDER BY number_of_users DESC


![image](https://github.com/user-attachments/assets/71535f91-2858-45cd-ad20-8cad54397c9f)


Observations.

- ***We can observe that 21% of the participants are involved in sendentary lifestyle based on their daily average steps***.
- ***28% of participants are somewhat active users***.
- ***47% (almost the half) of users are sedentary and low active***.
- ***25% of users have an average daily activity between active and highly active***.

---

**Average steps by day of the week**

Query.

	WITH inactivity_days AS (

	  SELECT 
	    Id,
	    activityDate,
	    FORMAT_DATE('%A', activityDate) AS day_of_the_week,
	    totalSteps
	
	  FROM `analysisbellabeat246.analysis.dailyActivity`
	
	  WHERE totalSteps != 0 AND totalIntensity != 0 AND MET_minutes != 0
	
	  ORDER BY Id, activityDate
	)
	
	SELECT 
	  day_of_the_week,
	  CAST(AVG(totalSteps) AS INT64) AS average_steps
	
	FROM inactivity_days
	
	GROUP BY day_of_the_week
	ORDER BY average_steps


![image](https://github.com/user-attachments/assets/17944b1f-e86b-4d6a-85ea-da255c9a272a)


Observations.

- ***Saturday was the day when users gave more steps throughout the week on average followed by Tuesday***.
- ***Sunday and Friday were the days when the users gave less steps on average***.
- ***We can notice a consistent increment of steps taken from Sunday to Tuesday, reaching the peak on Tuesday***.
- ***From Tuesday to Friday we can observe a consistent decrement in steps taken***.


---



 ### Users Meeting the 600 MET-Minutes Recommendation

- Users under 600 MET-minutes per week are not enough active to keep healthy lifestyle. They are not getting health benefits.
- Users over 600 MET-minutes per week are meeting the MET-minutes necessary for a good overall health. Besides maintaining a good health, the more MET-minutes accomplish during the week, the more health benefits.


Due to we are calculating MET-minutes per week, we need to fairly calculate this value through using full weeks. Therefore, we will filter out the data to include only the users who logged activity for all 7 days in each week. This is important because some of these weeks might have less than 7 active days for certain users.


Query.

	WITH weekly_METminutes AS (
	  SELECT
	    Id, 
	    CASE 
	    WHEN activityDate BETWEEN '2016-03-12' AND '2016-03-18' THEN 'Week 1'
	    WHEN activityDate BETWEEN '2016-03-19' AND '2016-03-25' THEN 'Week 2'
	    WHEN activityDate BETWEEN '2016-03-26' AND '2016-04-01' THEN 'Week 3'
	    WHEN activityDate BETWEEN '2016-04-02' AND '2016-04-08' THEN 'Week 4'
	    WHEN activityDate BETWEEN '2016-04-09' AND '2016-04-15' THEN 'Week 5'
	    WHEN activityDate BETWEEN '2016-04-16' AND '2016-04-22' THEN 'Week 6'
	    WHEN activityDate BETWEEN '2016-04-23' AND '2016-04-29' THEN 'Week 7'
	    WHEN activityDate BETWEEN '2016-04-30' AND '2016-05-06' THEN 'Week 8'
	    ELSE 'Week 9'    
	    END AS week,
	    COUNT(DISTINCT activityDate) AS active_days, -- count days user was active in week
	    SUM(MET_minutes) AS METs_minutes
	
	  FROM `analysisbellabeat246.analysis.dailyActivity`
	
	  WHERE totalSteps != 0 AND totalIntensity != 0 AND MET_minutes != 0
	  
	  GROUP BY Id, week
	),
	
	filtered_weeks AS (
	  SELECT
	    Id,
	    week,
	    METs_minutes
	    
	  FROM weekly_METminutes
	
	  WHERE active_days = 7 -- keep only users with 7 active days in the week
	)
	SELECT
	  week,
	  COUNTIF(METs_minutes < 600) AS goal_notAchieved,
	  COUNTIF(METs_minutes >= 600) AS goal_achieved
	
	FROM filtered_weeks
	
	GROUP BY week
	ORDER BY week



![image](https://github.com/user-attachments/assets/9a707c3c-1f13-4992-b86d-986aa11cca0d)


Observations.

- ***We can observe that the vast majority of participants achieved their MET-minutes/week recommendation for minimun physical activity to maintain their overall health. However, this doesn't tell us that these participants are involved in consistent high levels of physical activity or they are even getting extra health benefits like loosing weight or achieving their fitness goals.***
- ***We can notice that between 19 to 24 participants tracked their data consistenly completing full weeks using their wearables***.
- ***Week 9 doesn't appeared in the results this week only contains 6 days. It doesn't represent a full week, therefore we cannot draw fair MET-minutes/week results.***.
- ***The last week of the first month (week 4) was not only of the weeks with more users reaching their goal of 600 MET-minutes per week, but also the it was the week with more users wearing their devices more consistenly***.
  

### Physical Activity by Week

**Grouping data by week and physical activity**

To categorize the physical activity of users for this analysis, we will follow the MET-minutes/week categories created by this [study](https://www.healthdata.org/sites/default/files/methods_appendices/2021/lojustin_activity_writeup_gbd2020_AC_updated0131.pdf)

Physical activity level is categorised by total MET-minutes per week using four categories based on rounded values closest to the quartiles of the global distribution of total MET-minutes/week. The physical activity categories are defined in terms of weekly MET-mins as below:

• Level 0: <600 MET-min/week (inactive).

• Level 1: 600–3999 MET-min/week (low-active).

• Level 2: 4000–7,999 MET-min/week (moderately active).

• Level 3: ≥8,000 MET-min/week (highly active).



Query.

	WITH weekly_METminutes AS (
	  SELECT
	    Id,
	    CASE 
	    WHEN activityDate BETWEEN '2016-03-12' AND '2016-03-18' THEN 'Week 1'
	    WHEN activityDate BETWEEN '2016-03-19' AND '2016-03-25' THEN 'Week 2'
	    WHEN activityDate BETWEEN '2016-03-26' AND '2016-04-01' THEN 'Week 3'
	    WHEN activityDate BETWEEN '2016-04-02' AND '2016-04-08' THEN 'Week 4'
	    WHEN activityDate BETWEEN '2016-04-09' AND '2016-04-15' THEN 'Week 5'
	    WHEN activityDate BETWEEN '2016-04-16' AND '2016-04-22' THEN 'Week 6'
	    WHEN activityDate BETWEEN '2016-04-23' AND '2016-04-29' THEN 'Week 7'
	    WHEN activityDate BETWEEN '2016-04-30' AND '2016-05-06' THEN 'Week 8'
	    ELSE 'Week 9'    
	    END AS week,
	    COUNT(DISTINCT activityDate) AS active_days, -- count days user was active in week
	    CASE 
	    WHEN SUM(MET_minutes)<600 THEN 'Inactive'
	    WHEN SUM(MET_minutes) BETWEEN 600 AND 3999 THEN 'Low-active'
	    WHEN SUM(MET_minutes) BETWEEN 4000 AND 7999 THEN 'Moderately-active'
	    ELSE 'Highly-active' 
	    END AS physical_activity
	      
	  FROM `analysisbellabeat246.analysis.dailyActivity` 
	
	  WHERE totalSteps != 0 AND totalIntensity != 0 AND MET_minutes != 0
	
	  GROUP BY Id, week
	  ORDER BY Id, week
	)
	
	SELECT
	
	  week,
	  COUNT(Id) AS number_of_users,
	  physical_activity
	
	
	FROM weekly_METminutes
	
	WHERE active_days = 7 --keep only users with 7 active days in the week
	
	GROUP BY week, physical_activity
	ORDER BY week, physical_activity


 ---


![image](https://github.com/user-attachments/assets/64160dd0-469d-4efe-8cae-89b18a146eb3)


Observations.

-***We can observe a peak of 14 low-active users during the first week of the first month***.
- ***The weeks with more highly-active users were the week 1 and 4***.
- ***We can see a gradual increment of moderately-active users from week 1 to week 3, aftwerward the number of people moderately-active remains the same until the week 7 when there is peak of 10 moderately-active users, then this number drops in the week 8***.


---

![image](https://github.com/user-attachments/assets/308b24ea-75ba-4136-abdd-fdf47e21d259)


Observations.

1. Low-active users (red):

- It starts high at 14 users in Week 1.
- Sharp drop to 10 users in Week 2.
- Then fluctuates slightly between 10–12 users until Week 5.
- Gradual decline again to 10 users in weeks 6–8.

***There’s a clear downward trend, suggesting a slight shift of users away from the low-active category over time. Possibly some users moved up to moderately active***.

2. Moderately-active users (yellow).

- There is a steady increment of users in weeks 1-3.
- The number of users remain the same during weeks 3-6.
- There is a peak of 10 users in week 7.
- Sharp drop to 8 users in Week 8.

***There is a strong upward trend during weeks 1-7, reaching the peak of users moderately-active in week 7. This group is growing over time, especially during the first half. This indicates a positive trend where users are increasing their activity levels.***


3. Highly-active users (green).

- It starts at 4 users and fluctuates slightly during the first month (weeks 1-4) finishing with the same number of users as in the beginning.
- There is a drop to 2 users when starting off the second month (week 5).
- Then it fluctuates slightly again between 3–2 users until Week 8.

***There is a clear downward trend over the time of highly-active users. Highly active users reamin as the smallest group and there were even users that may have reduced their levels of activity over the time***.



---

**Physical Activity by Weekly Average MET-minutes**

Query.

	WITH weekly_METminutes AS(
	  SELECT
	  Id,
	  CASE 
	  WHEN activityDate BETWEEN '2016-03-12' AND '2016-03-18' THEN 'Week 1'
	  WHEN activityDate BETWEEN '2016-03-19' AND '2016-03-25' THEN 'Week 2'
	  WHEN activityDate BETWEEN '2016-03-26' AND '2016-04-01' THEN 'Week 3'
	  WHEN activityDate BETWEEN '2016-04-02' AND '2016-04-08' THEN 'Week 4'
	  WHEN activityDate BETWEEN '2016-04-09' AND '2016-04-15' THEN 'Week 5'
	  WHEN activityDate BETWEEN '2016-04-16' AND '2016-04-22' THEN 'Week 6'
	  WHEN activityDate BETWEEN '2016-04-23' AND '2016-04-29' THEN 'Week 7'
	  WHEN activityDate BETWEEN '2016-04-30' AND '2016-05-06' THEN 'Week 8' 
	  END AS week, 
	  COUNT(DISTINCT activityDate) AS active_days,
	  SUM(MET_minutes) AS METminutes
	      
	  FROM `analysisbellabeat246.analysis.dailyActivity`
	
	  WHERE totalSteps != 0 AND totalIntensity != 0 AND MET_minutes != 0
	
	  GROUP BY Id, week
	  ORDER BY Id, week
	)
	
	SELECT 
	  Id,
	  CASE 
	  WHEN AVG(METminutes)<600 THEN 'Inactive'
	  WHEN AVG(METminutes) BETWEEN 600 AND 3999 THEN 'Low-active'
	  WHEN AVG(METminutes) BETWEEN 4000 AND 7999 THEN 'Moderately-active'
	  ELSE 'Highly-active' 
	  END AS physical_activity,
	  CAST(AVG(METminutes) AS INT64) AS weekly_average_METminutes,
	
	FROM weekly_METminutes
	
	WHERE active_days = 7
	
	GROUP BY Id
	ORDER BY Id



![image](https://github.com/user-attachments/assets/8aebdee7-960c-4842-a1e0-d6c0cd4827ca)


According to [Medscape](https://www.medscape.com/viewarticle/867293), the data from a total 174 studies comprising 149,184,285 total person-years of follow-up, suggest that the more total regular daily physical activity one engages in — including recreation, transportation, occupational activity, and/or daily chores — the lower the risks for breast cancer, colon cancer, diabetes, ischemic heart disease, and ischemic stroke. However, significant reductions in those conditions were seen only with total activity levels considerably higher than the minimum 600 metabolic equivalent (MET) minutes per week recommended by the World Health Organization for health benefits. That 600 METs equates to about 150 minutes/week of brisk walking or 75 minutes/week of running. 

With the development of diabetes, for example, compared with no physical activity, those with 600 MET minutes per week (the minimum recommended level of activity) had a 2% lower risk. That risk reduction jumped by an additional 19% with an increase from 600 to 3600 METs/week. Gains were smaller above that, with the increase of total activity from 9000 to 12,000 MET minutes/week yielding only an additional 0.6% diabetes reduction.

Overall, compared with insufficiently active individuals (total activity < 600 MET minutes/week), the risk reduction for those in the highly active category (≥ 8000 MET minutes/week) was 14% for breast cancer; 21% for colon cancer; 28% for diabetes; 25% for ischemic heart disease; and 26% for ischemic stroke. 
Risks of the five conditions dropped significantly with an increase in MET minutes per week from 600 to 3000 to 4000, with less additive benefit seen above that level.


<img width="300" height="192" alt="image" src="https://github.com/user-attachments/assets/f5ce2bd4-ce39-4f35-ae55-cb48e1557f6a" />



Observations:

1. 600–3999 MET-min/week (low-active users).
   
- ***This is the largest group in the data with 18 users. Although, they were involved in low-active levels of activities and achieving the minimum WHO recommendation, they are still gaining sustantial health benefits***.
- ***12 users are achieving in average 600-3000 MET-minutes/week***.
- ***6 users are achieving in average 3000-4000 MET-minutes/week***.

2. 4000–7,999 MET-min/week (moderately active users).

- ***A smaller but still substantial number of users are in the moderately-active with 11 users in total. This group are not only gaining sustantial health benefits, but research shows the largest gains in disease prevention***.
- ***8 users are achieving in average 4000-6000 MET-minutes/week***.
- ***3 users are achieving in average 6000-8000 MET-minutes/week***.

4. ≥8,000 MET-min/week (highly active users).

- ***This is the smallest group with 2 users in total. There a big difference of almost 2000 MET-minutes/week between the user with more MET-minutes/week in moderately-active group with the user with less MET-minutes/week in the highly-active group***.
- ***The two users are not only achieving 8000 MET-minutes/week, but they are even reaching range between 9000-10000 MET-minutes/week***.
- ***Research suggests that health gains above 8,000 MET-min/week are smaller. For example, the diabetes risk drops only slightly (0.6%) when increasing from 9,000 to 12,000 MET-min/week***.



  
---

![image](https://github.com/user-attachments/assets/69c5735f-f715-403a-8706-79cac16cc59e)


Observations.

- ***More than half participants of the whole sample are low-active users, representing the 58%***.
- ***More than a third part of the total users are moderately-active***.
- ***A very small percentage of users are highly-active, representing only 6% of the whole***.


---




### Calories

The number of calories a person burn in a day depends on several factors such as:

- age
- sex
- height
- weight
- physical activity


**TDEE**

Total Daily Energy Expenditure (TDEE) is an estimation of how many calories a person burn per day when exercise is taken into account.
This involves multiplying a person’s basal metabolic rate (BMR) by their average daily activity level.


***What is BMR?***

BMR stands for basal metabolic rate. It is the number of calories a person needs to stay alive. This includes basic functions such as:

- breathing
- heart rate and blood flow
- metabolism (digestion and nutrient absorption)
- cell function, growth, and repair


Harris-Benedict Equation Based Formula.

For Men: BMR = 88.362 + (13.397 x weight in kg) + (4.799 x height in cm) - (5.677 x age in years).

For Women: BMR = 447.593 + (9.247 x weight in kg) + (3.098 x height in cm) - (4.330 x age in years).


***Activity Factor***.

Activity factors range from sedentary (1.2) to extra active (1.9)

Sedentary (little to no daily exercise): BMR x 1.2
Lightly Active (light movement or 1-2 days per week of training): BMR x 1.375
Moderately Active (3-5 days per week of daily exercise): BMR x 1.55
Very Active (intense short-term and chronic interval training or active sports): BMR x 1.725
Extra Active (physically demanding jobs or elite-level athletes): BMR x 1.9


![Image](https://github.com/user-attachments/assets/fbbfbc5f-b521-4367-bba7-618ae7eed67d)



---

Due to lack of overall information about users' physical characteristics such as age, sex, height, and weight for this analysis, we cannot accurately determine whether the calories burnt by each user is aligned with their personal needs and goals. 
However, I used an overall reference point about total daily energy expenditure for average adults based on [ATHLEAN‑X TDEE Calculator](https://learn.athleanx.com/calculators/tdee-calculator?utm_source=chatgpt.com) website.

***Nevertheless, these values don't reflect the real total daily energy expenditure for each user in this analysis. It is only an approach to understand the calories burnt by each user  in the data***


Total Daily Energy Expenditure by activity level.

| **Sedentary** | **Lightly Active** | Moderately Active | Very Active | Extremely Active |
| --- | --- | --- | --- | --- |
| 2,053 calories | 2,321 calories | 2,679 calories | 3,036 calories | 3,393 calories |

---

https://www.healthline.com/health/how-to-calculate-your-basal-metabolic-rate

https://tdeecalculator.net/

https://www.calculator.net/tdee-calculator.html

https://learn.athleanx.com/calculators/tdee-calculator

https://mitchcalvert.com/golden-ticket-fat-loss/


Query.

	SELECT  
	  Id, 
	  activityDate,
	  CASE 
	  WHEN calories < 2000 THEN 'Sedentary'
	  WHEN calories BETWEEN 2000 AND 2300 THEN 'Lightly Active'
	  WHEN calories BETWEEN 2301 AND 2600 THEN 'Moderately Actvie'
	  WHEN calories BETWEEN 2601 AND 3000 THEN 'Very Active'
	  ELSE 'Extremely Active'
	  END AS total_daily_energy_expenditure,
	  CASE
	  WHEN activityDate BETWEEN '2016-03-12' AND '2016-03-18' THEN 'Week 1'
	  WHEN activityDate BETWEEN '2016-03-19' AND '2016-03-25' THEN 'Week 2'
	  WHEN activityDate BETWEEN '2016-03-26' AND '2016-04-01' THEN 'Week 3'
	  WHEN activityDate BETWEEN '2016-04-02' AND '2016-04-08' THEN 'Week 4'
	  WHEN activityDate BETWEEN '2016-04-09' AND '2016-04-15' THEN 'Week 5'
	  WHEN activityDate BETWEEN '2016-04-16' AND '2016-04-22' THEN 'Week 6'
	  WHEN activityDate BETWEEN '2016-04-23' AND '2016-04-29' THEN 'Week 7'
	  WHEN activityDate BETWEEN '2016-04-30' AND '2016-05-06' THEN 'Week 8'
	  ELSE 'Week 9'
	  END AS week,
	  
	FROM `analysisbellabeat246.analysis.dailyActivity` 
	
	ORDER BY Id, activityDate



### Weekly Activity

	Query.
	
	SELECT  
	  Id,
	  CASE 
	  WHEN activityDate BETWEEN '2016-03-12' AND '2016-03-18' THEN 'Week 1'
	  WHEN activityDate BETWEEN '2016-03-19' AND '2016-03-26' THEN 'Week 2'
	  WHEN activityDate BETWEEN '2016-03-27' AND '2016-04-02' THEN 'Week 3'
	  WHEN activityDate BETWEEN '2016-04-03' AND '2016-04-09' THEN 'Week 4'
	  WHEN activityDate BETWEEN '2016-04-10' AND '2016-04-16' THEN 'Week 5'
	  WHEN activityDate BETWEEN '2016-04-17' AND '2016-04-23' THEN 'Week 6'
	  WHEN activityDate BETWEEN '2016-04-24' AND '2016-04-30' THEN 'Week 7'
	  WHEN activityDate BETWEEN '2016-05-01' AND '2016-05-07' THEN 'Week 8'
	  ELSE 'Week 9'    
	  END AS week,
	  SUM(calories) AS calories,
	  SUM(totalIntensity) AS totalIntensity,
	  SUM(sedentaryMinutes) AS sedentaryMinutes,
	  SUM(lightlyActiveMinutes) AS lightlyActiveMinutes,
	  SUM(fairlyActiveMinutes) AS fairlyActiveMinutes,
	  SUM(veryActiveMinutes) AS veryActiveMinutes,
	  SUM(MET_minutes) AS MET_minutes,
	  SUM(totalSteps) As totalSteps  
	
	FROM `analysisbellabeat246.analysis.dailyActivity` 
	
	GROUP BY Id, week
	ORDER BY Id, week
